{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ứng dụng mạng Neural trong Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import một số thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import time\n",
    "import matplotlib.text as plttext\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hàm tạo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create 2D dataset with 3 label\n",
    "\n",
    "# Random\n",
    "rng = np.random.RandomState(1311)\n",
    "\n",
    "def create_data(num_sample=None):\n",
    "    \"\"\"\n",
    "    Generate samples of 3 classes using normal distribution\n",
    "    + type(num_sample) int\n",
    "    + param num_sample: number of sample to be generated for each class\n",
    "    + return: data and label for each class\n",
    "    \"\"\"\n",
    "    I = np.eye(3, dtype=np.float32)\n",
    "    \n",
    "    if(num_sample == None):\n",
    "        num_sample = 100\n",
    "        \n",
    "    # Generate first class\n",
    "    m1 = np.asarray([0, 0], dtype=np.float32)\n",
    "    cov1 = np.asarray([[0.5, 0], [0, 0.5]], dtype=np.float32)\n",
    "    data1 = rng.multivariate_normal(m1, cov1, num_sample)\n",
    "    label1 = np.ones((num_sample), dtype=np.uint16) - 1\n",
    "    label1 = I[label1,:]\n",
    "    \n",
    "    # Generate second class\n",
    "    m2 = np.asarray([5,5], dtype=np.float32)\n",
    "    cov2 = np.asarray([[0.5, 0], [0, 0.5]], dtype=np.float32)\n",
    "    data2 = rng.multivariate_normal(m2, cov2, num_sample)\n",
    "    label2 = np.ones((num_sample), dtype=np.uint16)\n",
    "    label2 = I[label2, :]\n",
    "    \n",
    "    # Generate third class\n",
    "    noise = np.abs((np.reshape(rng.normal(0, 0.01, num_sample), (num_sample,1))))\n",
    "    S1 = np.asarray([[1, 0], [0, 0.7]], dtype=np.float32)\n",
    "    S2 = np.asarray([[4, 0], [0, 4]], dtype=np.float32)\n",
    "    m3 = np.asarray([0.5, 0.5], dtype=np.float32)\n",
    "    cov3 = np.asarray([[0.5, 0], [0, 0.5]], dtype=np.float32)\n",
    "    data3 = rng.multivariate_normal(m3, cov3, num_sample)\n",
    "    data3 = data3/np.repeat(np.sqrt(np.sum(data3**2, 1, keepdims=True) + noise), 2, 1)\n",
    "    data3 = np.dot(S2, np.dot(S1, data3.T)).T\n",
    "    \n",
    "    d = np.sqrt(np.sum(data3**2, 1, keepdims=True))\n",
    "    d1 = np.reshape(d<2.5, (num_sample))\n",
    "    data3[np.ix_(d1, [True, True])] = data3[np.ix_(d1, [True, True])]/np.repeat(d[d1], 2, 1)\n",
    "\n",
    "    label3 = np.ones((num_sample), dtype=np.uint16) + 1\n",
    "    label3 = I[label3, :]\n",
    "\n",
    "    return (data1, label1, data2, label2, data3, label3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hàm chia tập dataset để Train, Test và Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def devideDataset(data1, label1, data2, label2, data3, label3, numOfTrain, numOfValidation):\n",
    "    train_X = np.concatenate((data1[0:numOfTrain, :],\n",
    "                              data2[0:numOfTrain, :],\n",
    "                              data3[0:numOfTrain, :]))\n",
    "\n",
    "    train_Y = np.concatenate((label1[0:numOfTrain, :],\n",
    "                              label2[0:numOfTrain, :],\n",
    "                              label3[0:numOfTrain, :]))\n",
    "\n",
    "    val_X = np.concatenate((data1[numOfTrain:(numOfTrain + numOfValidation), :],\n",
    "                              data2[numOfTrain:(numOfTrain + numOfValidation), :],\n",
    "                              data3[numOfTrain:(numOfTrain + numOfValidation), :]))\n",
    "\n",
    "    val_Y = np.concatenate((label1[numOfTrain:(numOfTrain + numOfValidation), :],\n",
    "                              label2[numOfTrain:(numOfTrain + numOfValidation), :],\n",
    "                              label3[numOfTrain:(numOfTrain + numOfValidation), :]))\n",
    "\n",
    "    test_X = np.concatenate((data1[(numOfTrain + numOfValidation):, :],\n",
    "                            data2[(numOfTrain + numOfValidation):, :],\n",
    "                            data3[(numOfTrain + numOfValidation):, :]))\n",
    "\n",
    "    test_Y = np.concatenate((label1[(numOfTrain + numOfValidation):, :],\n",
    "                            label2[(numOfTrain + numOfValidation):, :],\n",
    "                            label3[(numOfTrain + numOfValidation):, :]))\n",
    "\n",
    "    return (train_X, train_Y, val_X, val_Y, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_data(data1, data2, data3, figure_num):\n",
    "    if(data1.shape[0] > 1000):\n",
    "        sizeOfPoint = 10\n",
    "    else:\n",
    "        sizeOfPoint = 50\n",
    "    \n",
    "    plt.figure(figure_num)\n",
    "    plt.axis('equal')\n",
    "    plt.scatter(data1[:,0], data1[:,1], sizeOfPoint, 'r', label='class_red')\n",
    "    plt.scatter(data2[:, 0], data2[:, 1], sizeOfPoint, 'g', label='class_green')\n",
    "    plt.scatter(data3[:, 0], data3[:, 1], sizeOfPoint, 'b', label='class_blue')\n",
    "    plt.xlabel('$x$', fontsize=15)\n",
    "    plt.ylabel('$y$', fontsize=15)\n",
    "    plt.grid()\n",
    "    plt.legend(loc=3)\n",
    "    plt.show()\n",
    "    \n",
    "def find_decision_boundary(X, Y, W1, b1, W2, b2, config):\n",
    "    num_fake_data = 150\n",
    "    num_train_sample = X.shape[0]\n",
    "    num_feature = X.shape[1]\n",
    "    num_hidden_node = W1.shape[1]\n",
    "    num_class = Y.shape[1]\n",
    "\n",
    "    demo_type = config['demo_type']\n",
    "    activation_function_type = config['activation_function']\n",
    "    min_X1 = np.min(X[:, 0]) - 0.1\n",
    "    max_X1 = np.max(X[:, 0]) + 0.1\n",
    "    min_X2 = np.min(X[:, 1]) - 0.1\n",
    "    max_X2 = np.max(X[:, 1]) + 0.1\n",
    "\n",
    "    # Create grid data\n",
    "    X1 = np.linspace(min_X1, max_X1, num_fake_data)\n",
    "    X2 = np.linspace(min_X2, max_X2, num_fake_data)\n",
    "    xv, yv = np.meshgrid(X1, X2)\n",
    "    xv = xv.flatten().astype(np.float32).reshape((num_fake_data ** 2, 1))\n",
    "    yv = yv.flatten().astype(np.float32).reshape((num_fake_data ** 2, 1))\n",
    "    X = np.concatenate((xv, yv), 1)\n",
    "\n",
    "    del xv\n",
    "    del yv\n",
    "\n",
    "    a1 = np.dot(X, W1) + b1\n",
    "    z1 = activation_function(a1, activation_function_type)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    # pred = np.repeat(np.argmax(a2, 1).reshape((num_fake_data**2, 1)), 2, 1)\n",
    "    pred = np.argmax(a2, 1)\n",
    "    grid0 = X[pred == 0, :]\n",
    "    grid1 = X[pred == 1, :]\n",
    "    grid2 = X[pred == 2, :]\n",
    "\n",
    "    grid0 = grid0.reshape((grid0.shape[0], num_feature))\n",
    "    grid1 = grid1.reshape((grid1.shape[0], num_feature))\n",
    "    grid2 = grid2.reshape((grid2.shape[0], num_feature))\n",
    "\n",
    "    return (grid0, grid1, grid2)\n",
    "\n",
    "\n",
    "def visualize_decision_grid(data1, data2, data3, figure_num):\n",
    "    plt.figure(figure_num)\n",
    "    plt.axis('equal')\n",
    "    plt.scatter(data1[:, 0], data1[:, 1], 10, c=[1, 0.5, 0.5], marker='+')\n",
    "    plt.scatter(data2[:, 0], data2[:, 1], 10, c=[0.5, 1, 0.5], marker='+')\n",
    "    plt.scatter(data3[:, 0], data3[:, 1], 10, c=[0.5, 0.5, 1], marker='+')\n",
    "    bp = 1\n",
    "    \n",
    "def train_draw(X, Y, W1, b1, W2, b2, config, all_cost, i, J):\n",
    "    # Display the training process\n",
    "\n",
    "    num_hidden_node = config['num_hidden_node']\n",
    "    num_train_per_class = config['num_train_per_class']\n",
    "    train_method = config['train_method']\n",
    "    save_img = config['save_img']\n",
    "    demo_type = config['demo_type']\n",
    "\n",
    "    lr = config['lr']\n",
    "\n",
    "    pylab.clf()\n",
    "    f = plt.figure(2, figsize=(10, 5))\n",
    "#     f = plt.figure(2, figsize=(12, 6))\n",
    "#     f = plt.figure(2)\n",
    "\n",
    "    title = '%s with %d hidden nodes, lr = %.4g, %d epoch, cost = %.4g' % (train_method, num_hidden_node, lr, i, J)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    [grid1, grid2, grid3] = find_decision_boundary(X, Y, W1, b1, W2, b2, config)\n",
    "\n",
    "    visualize_decision_grid(grid1, grid2, grid3, 2)\n",
    "\n",
    "    visualize_data(X[0:num_train_per_class, :],\n",
    "                   X[num_train_per_class:num_train_per_class * 2, :],\n",
    "                   X[num_train_per_class * 2:, :], 2)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(all_cost, 'b')\n",
    "    plt.xlabel('Iter')\n",
    "    plt.ylabel('Cost')\n",
    "\n",
    "    f.suptitle(title, fontsize=15)\n",
    "    plt.pause(0.1)\n",
    "\n",
    "    pylab.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Các hàm sử dụng huấn luyện mạng Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Activation functions\n",
    "def sigmoid(X, bp = False):\n",
    "    if (not bp):\n",
    "        return 1.0/(1.0 + np.exp(-X))\n",
    "    else:\n",
    "        sig = 1.0/(1.0 + np.exp(-X))\n",
    "        return sig * (1 - sig)\n",
    "\n",
    "def softmax(X):\n",
    "    # Assume that the second dim is the feature dim\n",
    "    max_input = np.max(X, 1, keepdims=True)\n",
    "    X_max = X - max_input\n",
    "    e = np.exp(X_max)\n",
    "    sum_e = np.sum(e, 1, keepdims=True)\n",
    "    return e / sum_e\n",
    "\n",
    "def relu(X, bp = False):\n",
    "    result = X\n",
    "    if (not bp):\n",
    "        result = X\n",
    "        result[X < 0] = 0\n",
    "    else:\n",
    "        result[X > 0] = 1\n",
    "        result[X <= 0] = 0\n",
    "    return result\n",
    "\n",
    "def activation_function(X, type, bp = False):\n",
    "    if (type == \"sigmoid\"):\n",
    "        return sigmoid(X, bp)\n",
    "    elif (type == \"relu\"):\n",
    "        return relu(X, bp)\n",
    "    else:\n",
    "        raise ValueError(\"Activation function not recognized\")\n",
    "        \n",
    "# Softmax_log_loss\n",
    "def softmax_log_loss(X, Y, bp=False):\n",
    "    # Perform checking\n",
    "    assert len(X.shape) == 2, \"X should have a shape of (num_sample, num_class)\"\n",
    "    assert len(Y.shape) == 2, \"Y should have a shape of (num_sample, num_class)\"\n",
    "    assert (X.shape[0] == Y.shape[0]) and (X.shape[1] == Y.shape[1]), \"Predictions and labels should have the same shape\"\n",
    "    n = Y.shape[0]\n",
    "    \n",
    "    if (not bp):\n",
    "        # Perform feedforward\n",
    "        # Assume that the second dim is the feature dim\n",
    "        xdev = X - np.max(X, 1, keepdims=True)\n",
    "        lsm = xdev - np.log(np.sum(np.exp(xdev), axis=1, keepdims=True))\n",
    "        return -np.sum(lsm*Y) / n\n",
    "    else:\n",
    "        # Perform backprob and return the derivatives\n",
    "        xmax = np.max(X, 1, keepdims=True)\n",
    "        ex = np.exp(X-xmax)\n",
    "        dFdX = ex/np.sum(ex, 1, keepdims=True)\n",
    "        dFdX[Y.astype(bool)] = (dFdX[Y.astype(bool)]-1)\n",
    "        dFdX = dFdX / n\n",
    "        # dFdX = (dFdX - 1) / n\n",
    "        return dFdX\n",
    "    \n",
    "def get_grad(X, Y, W1, b1, W2, b2, config):\n",
    "    activation_function_type = config['activation_function']\n",
    "\n",
    "    num_train_sample = X.shape[0]\n",
    "    num_feature = X.shape[1]\n",
    "    num_hidden_node = W1.shape[1]\n",
    "    num_class = Y.shape[1]\n",
    "\n",
    "    a1 = np.dot(X, W1) + b1\n",
    "    z1 = activation_function(a1, activation_function_type)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "\n",
    "    # Calculate W2 and b2 gradient\n",
    "    dJ_da2 = softmax_log_loss(a2, Y, True)\n",
    "    # These are basically dJ_da2 but are repeated so we can multiply them with dJ_dW2 and dJ_dz1\n",
    "    dJ_da2b = np.sum(dJ_da2, 0, keepdims=True)\n",
    "    dJ_da2W = np.repeat(dJ_da2.reshape((num_train_sample, 1, num_class)), num_hidden_node, 1)\n",
    "    dJ_da2z1 = np.repeat(dJ_da2.reshape((num_train_sample, 1, num_class)), num_hidden_node, 1)\n",
    "\n",
    "    da2_dW2 = np.repeat(z1.reshape((num_train_sample, num_hidden_node, 1)), num_class, 2)\n",
    "    da2_db2 = 1\n",
    "    da2_dz1 = np.repeat(W2.reshape(1, num_hidden_node, num_class), num_train_sample, 0)\n",
    "\n",
    "    dJ_dW2 = np.sum(dJ_da2W * da2_dW2, 0)\n",
    "    dJ_db2 = da2_db2 * dJ_da2b\n",
    "    dJ_dz1 = np.sum(dJ_da2z1 * da2_dz1, 2)\n",
    "\n",
    "    # Calculate W1 and b1 gradient\n",
    "    dJ_dz1_dW1 = np.repeat(dJ_dz1.reshape((num_train_sample, 1, num_hidden_node)), num_feature, 1)\n",
    "    dz1_da1 = activation_function(a1, activation_function_type, True)\n",
    "    dz1_da1_W1 = np.repeat(dz1_da1.reshape((num_train_sample, 1, num_hidden_node)), num_feature, 1)\n",
    "    da1_dW1 = np.repeat(X.reshape((num_train_sample, num_feature, 1)), num_hidden_node, 2)\n",
    "    da1_db1 = 1\n",
    "\n",
    "    dJ_dW1 = np.sum(dJ_dz1_dW1 * dz1_da1_W1 * da1_dW1, 0)\n",
    "    dJ_db1 = np.sum(dJ_dz1 * dz1_da1 * da1_db1, 0, keepdims=True)\n",
    "\n",
    "    # NumericalGradientCheck(X, Y, W1, b1, W2, b2, dJ_db1)\n",
    "\n",
    "    return (dJ_dW1, dJ_db1, dJ_dW2, dJ_db2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification(train_X, train_Y, val_X, val_Y, test_X, test_Y, config):\n",
    "    # This is to demonstrate the process of learning a simple one hidden-layer NN\n",
    "    # Input kernel: linear\n",
    "    # Num hidden layer: 1\n",
    "    # Learning method: SGD with momentum\n",
    "    \n",
    "#     print \"Training dataset\"\n",
    "#     print train_X\n",
    "#     print train_Y\n",
    "\n",
    "    # Parse param from config\n",
    "    learning_rate = config['lr']\n",
    "    numOfEpoch = config['num_epoch'] # numOfEpoch = num of iteration, eacch iteration = ?\n",
    "    num_train_per_class = config['num_train_per_class']\n",
    "    numOfHiddenNodes = config['num_hidden_node']\n",
    "    momentum_rate = config['momentum']\n",
    "    display_rate = config['display_rate']\n",
    "    activation_function_type = config['activation_function']\n",
    "\n",
    "    numOfTrainSamples = train_X.shape[0]\n",
    "    numOfFeatures = train_X.shape[1]\n",
    "    numOfClass = train_Y.shape[1]\n",
    "\n",
    "    # Create a weight matrix of shape (2, num_hidden_node)\n",
    "    W1 = rng.randn(numOfFeatures, numOfHiddenNodes)\n",
    "    b1 = rng.randn(1, numOfHiddenNodes)\n",
    "    \n",
    "    print \"Weight params:\"\n",
    "#     print W1\n",
    "#     print b1\n",
    "\n",
    "    # Create the output of weight matrix\n",
    "    W2 = rng.randn(numOfHiddenNodes, numOfClass)\n",
    "    b2 = rng.randn(1, numOfClass)\n",
    "#     print W2\n",
    "#     print b2\n",
    "    \n",
    "    # Create momentum storage\n",
    "    W1m = np.zeros_like(W1)\n",
    "    b1m = np.zeros_like(b1)\n",
    "    W2m = np.zeros_like(W2)\n",
    "    b2m = np.zeros_like(b2)\n",
    "    \n",
    "    # Training\n",
    "    numOfTrainSamples = 1\n",
    "    pylab.ion()\n",
    "    pylab.show()\n",
    "    all_cost = []\n",
    "    numOfEpoch = 1000\n",
    "    for i in range(0, numOfEpoch):\n",
    "        # Calculate the loss\n",
    "        a1 = np.dot(train_X, W1) + b1\n",
    "        z1 = activation_function(a1, activation_function_type)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        J = softmax_log_loss(a2, train_Y)\n",
    "        \n",
    "        # Doing backprop\n",
    "        print('[Iter %d] Train loss: %f' % (i, J))\n",
    "\n",
    "        dJ_dW1, dJ_db1, dJ_dW2, dJ_db2 = get_grad(train_X, train_Y, W1, b1, W2, b2, config)\n",
    "        # NumericalGradientCheck(train_X, train_Y, W1, b1, W2, b2, dJ_db1)\n",
    "\n",
    "        W1m = W1m * momentum_rate + learning_rate * dJ_dW1 * learning_rate\n",
    "        b1m = b1m * momentum_rate + learning_rate * dJ_db1 * learning_rate\n",
    "        W2m = W2m * momentum_rate + learning_rate * dJ_dW2 * learning_rate\n",
    "        b2m = b2m * momentum_rate + learning_rate * dJ_db2 * learning_rate\n",
    "\n",
    "        W1 = W1 - W1m\n",
    "        b1 = b1 - b1m\n",
    "        W2 = W2 - W2m\n",
    "        b2 = b2 - b2m\n",
    "\n",
    "        all_cost.append(J)\n",
    "    \n",
    "#         if (i % display_rate == 0):\n",
    "#             config['train_method'] = 'sgdm'\n",
    "#             train_draw(train_X, train_Y, W1, b1, W2, b2, config, all_cost, i, J)\n",
    "\n",
    "        bp = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hàm main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAw4AAAIZCAYAAAAP5mjaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wBkLTCkCUPgYwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11864b8d0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 268,
       "width": 391
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "numOfSample = 2000\n",
    "numOfTrain = 1500\n",
    "numOfValidation = 250\n",
    "(data1, label1, data2, label2, data3, label3) = create_data(numOfSample)\n",
    "(train_X, train_Y, val_X, val_Y, test_X, test_Y) = devideDataset(data1, label1, data2, label2, data3, label3,\n",
    "                                                                    numOfTrain, numOfValidation)\n",
    "# Visualize dataset\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "visualize_data(data1, data2, data3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-process data\n",
    "mean_X = np.mean(train_X, 0, keepdims=True)\n",
    "std_X = np.std(train_X, 0, keepdims=True)\n",
    "train_X = (train_X - mean_X) / std_X\n",
    "val_X = (val_X - mean_X) / std_X\n",
    "test_X = (test_X - mean_X) / std_X\n",
    "\n",
    "# Set configuration\n",
    "config = {}\n",
    "config['demo_type'] = \"classifynnsgd\"\n",
    "config['save_img'] = False\n",
    "config['num_epoch'] = 1000\n",
    "config['lr'] = 0.8\n",
    "config['num_train_per_class'] = numOfTrain\n",
    "config['num_hidden_node'] = 4\n",
    "config['activation_function'] = 'relu'\n",
    "config['display_rate'] = 10 # epochs per display time\n",
    "config['momentum'] = 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight params:\n",
      "[Iter 0] Train loss: 3.188622\n",
      "[Iter 1] Train loss: 1.080358\n",
      "[Iter 2] Train loss: 1.307300\n",
      "[Iter 3] Train loss: 0.924692\n",
      "[Iter 4] Train loss: 0.587484\n",
      "[Iter 5] Train loss: 0.601433\n",
      "[Iter 6] Train loss: 0.759400\n",
      "[Iter 7] Train loss: 0.657361\n",
      "[Iter 8] Train loss: 0.499608\n",
      "[Iter 9] Train loss: 0.448768\n",
      "[Iter 10] Train loss: 0.439799\n",
      "[Iter 11] Train loss: 0.440384\n",
      "[Iter 12] Train loss: 0.438540\n",
      "[Iter 13] Train loss: 0.430272\n",
      "[Iter 14] Train loss: 0.416143\n",
      "[Iter 15] Train loss: 0.400319\n",
      "[Iter 16] Train loss: 0.388153\n",
      "[Iter 17] Train loss: 0.381535\n",
      "[Iter 18] Train loss: 0.378318\n",
      "[Iter 19] Train loss: 0.375440\n",
      "[Iter 20] Train loss: 0.371569\n",
      "[Iter 21] Train loss: 0.367086\n",
      "[Iter 22] Train loss: 0.361895\n",
      "[Iter 23] Train loss: 0.354883\n",
      "[Iter 24] Train loss: 0.345387\n",
      "[Iter 25] Train loss: 0.333542\n",
      "[Iter 26] Train loss: 0.319363\n",
      "[Iter 27] Train loss: 0.304688\n",
      "[Iter 28] Train loss: 0.291131\n",
      "[Iter 29] Train loss: 0.279839\n",
      "[Iter 30] Train loss: 0.269751\n",
      "[Iter 31] Train loss: 0.259181\n",
      "[Iter 32] Train loss: 0.246117\n",
      "[Iter 33] Train loss: 0.230253\n",
      "[Iter 34] Train loss: 0.212173\n",
      "[Iter 35] Train loss: 0.191441\n",
      "[Iter 36] Train loss: 0.169434\n",
      "[Iter 37] Train loss: 0.149038\n",
      "[Iter 38] Train loss: 0.135045\n",
      "[Iter 39] Train loss: 0.129220\n",
      "[Iter 40] Train loss: 0.128489\n",
      "[Iter 41] Train loss: 0.129677\n",
      "[Iter 42] Train loss: 0.131419\n",
      "[Iter 43] Train loss: 0.133213\n",
      "[Iter 44] Train loss: 0.134856\n",
      "[Iter 45] Train loss: 0.136176\n",
      "[Iter 46] Train loss: 0.137201\n",
      "[Iter 47] Train loss: 0.137971\n",
      "[Iter 48] Train loss: 0.138437\n",
      "[Iter 49] Train loss: 0.138496\n",
      "[Iter 50] Train loss: 0.138212\n",
      "[Iter 51] Train loss: 0.137595\n",
      "[Iter 52] Train loss: 0.136660\n",
      "[Iter 53] Train loss: 0.135444\n",
      "[Iter 54] Train loss: 0.134021\n",
      "[Iter 55] Train loss: 0.132459\n",
      "[Iter 56] Train loss: 0.130831\n",
      "[Iter 57] Train loss: 0.129205\n",
      "[Iter 58] Train loss: 0.127668\n",
      "[Iter 59] Train loss: 0.126311\n",
      "[Iter 60] Train loss: 0.125092\n",
      "[Iter 61] Train loss: 0.123976\n",
      "[Iter 62] Train loss: 0.122945\n",
      "[Iter 63] Train loss: 0.121930\n",
      "[Iter 64] Train loss: 0.120922\n",
      "[Iter 65] Train loss: 0.119967\n",
      "[Iter 66] Train loss: 0.119097\n",
      "[Iter 67] Train loss: 0.118304\n",
      "[Iter 68] Train loss: 0.117553\n",
      "[Iter 69] Train loss: 0.116930\n",
      "[Iter 70] Train loss: 0.116433\n",
      "[Iter 71] Train loss: 0.116071\n",
      "[Iter 72] Train loss: 0.115826\n",
      "[Iter 73] Train loss: 0.115621\n",
      "[Iter 74] Train loss: 0.115445\n",
      "[Iter 75] Train loss: 0.115182\n",
      "[Iter 76] Train loss: 0.114738\n",
      "[Iter 77] Train loss: 0.114186\n",
      "[Iter 78] Train loss: 0.113710\n",
      "[Iter 79] Train loss: 0.113304\n",
      "[Iter 80] Train loss: 0.112970\n",
      "[Iter 81] Train loss: 0.112597\n",
      "[Iter 82] Train loss: 0.112258\n",
      "[Iter 83] Train loss: 0.112000\n",
      "[Iter 84] Train loss: 0.111818\n",
      "[Iter 85] Train loss: 0.111609\n",
      "[Iter 86] Train loss: 0.111360\n",
      "[Iter 87] Train loss: 0.111094\n",
      "[Iter 88] Train loss: 0.110821\n",
      "[Iter 89] Train loss: 0.110557\n",
      "[Iter 90] Train loss: 0.110336\n",
      "[Iter 91] Train loss: 0.110171\n",
      "[Iter 92] Train loss: 0.110048\n",
      "[Iter 93] Train loss: 0.109949\n",
      "[Iter 94] Train loss: 0.109856\n",
      "[Iter 95] Train loss: 0.109741\n",
      "[Iter 96] Train loss: 0.109615\n",
      "[Iter 97] Train loss: 0.109465\n",
      "[Iter 98] Train loss: 0.109319\n",
      "[Iter 99] Train loss: 0.109183\n",
      "[Iter 100] Train loss: 0.109070\n",
      "[Iter 101] Train loss: 0.108979\n",
      "[Iter 102] Train loss: 0.108893\n",
      "[Iter 103] Train loss: 0.108803\n",
      "[Iter 104] Train loss: 0.108709\n",
      "[Iter 105] Train loss: 0.108605\n",
      "[Iter 106] Train loss: 0.108504\n",
      "[Iter 107] Train loss: 0.108407\n",
      "[Iter 108] Train loss: 0.108318\n",
      "[Iter 109] Train loss: 0.108239\n",
      "[Iter 110] Train loss: 0.108163\n",
      "[Iter 111] Train loss: 0.108089\n",
      "[Iter 112] Train loss: 0.108003\n",
      "[Iter 113] Train loss: 0.107906\n",
      "[Iter 114] Train loss: 0.107809\n",
      "[Iter 115] Train loss: 0.107690\n",
      "[Iter 116] Train loss: 0.107555\n",
      "[Iter 117] Train loss: 0.107423\n",
      "[Iter 118] Train loss: 0.107280\n",
      "[Iter 119] Train loss: 0.107124\n",
      "[Iter 120] Train loss: 0.106975\n",
      "[Iter 121] Train loss: 0.106832\n",
      "[Iter 122] Train loss: 0.106705\n",
      "[Iter 123] Train loss: 0.106589\n",
      "[Iter 124] Train loss: 0.106474\n",
      "[Iter 125] Train loss: 0.106359\n",
      "[Iter 126] Train loss: 0.106249\n",
      "[Iter 127] Train loss: 0.106139\n",
      "[Iter 128] Train loss: 0.106028\n",
      "[Iter 129] Train loss: 0.105919\n",
      "[Iter 130] Train loss: 0.105806\n",
      "[Iter 131] Train loss: 0.105694\n",
      "[Iter 132] Train loss: 0.105588\n",
      "[Iter 133] Train loss: 0.105488\n",
      "[Iter 134] Train loss: 0.105398\n",
      "[Iter 135] Train loss: 0.105315\n",
      "[Iter 136] Train loss: 0.105233\n",
      "[Iter 137] Train loss: 0.105148\n",
      "[Iter 138] Train loss: 0.105066\n",
      "[Iter 139] Train loss: 0.104990\n",
      "[Iter 140] Train loss: 0.104919\n",
      "[Iter 141] Train loss: 0.104852\n",
      "[Iter 142] Train loss: 0.104788\n",
      "[Iter 143] Train loss: 0.104730\n",
      "[Iter 144] Train loss: 0.104676\n",
      "[Iter 145] Train loss: 0.104622\n",
      "[Iter 146] Train loss: 0.104571\n",
      "[Iter 147] Train loss: 0.104524\n",
      "[Iter 148] Train loss: 0.104482\n",
      "[Iter 149] Train loss: 0.104438\n",
      "[Iter 150] Train loss: 0.104391\n",
      "[Iter 151] Train loss: 0.104346\n",
      "[Iter 152] Train loss: 0.104301\n",
      "[Iter 153] Train loss: 0.104260\n",
      "[Iter 154] Train loss: 0.104219\n",
      "[Iter 155] Train loss: 0.104178\n",
      "[Iter 156] Train loss: 0.104138\n",
      "[Iter 157] Train loss: 0.104102\n",
      "[Iter 158] Train loss: 0.104068\n",
      "[Iter 159] Train loss: 0.104037\n",
      "[Iter 160] Train loss: 0.104007\n",
      "[Iter 161] Train loss: 0.103975\n",
      "[Iter 162] Train loss: 0.103942\n",
      "[Iter 163] Train loss: 0.103902\n",
      "[Iter 164] Train loss: 0.103858\n",
      "[Iter 165] Train loss: 0.103814\n",
      "[Iter 166] Train loss: 0.103771\n",
      "[Iter 167] Train loss: 0.103731\n",
      "[Iter 168] Train loss: 0.103694\n",
      "[Iter 169] Train loss: 0.103660\n",
      "[Iter 170] Train loss: 0.103628\n",
      "[Iter 171] Train loss: 0.103598\n",
      "[Iter 172] Train loss: 0.103569\n",
      "[Iter 173] Train loss: 0.103542\n",
      "[Iter 174] Train loss: 0.103509\n",
      "[Iter 175] Train loss: 0.103476\n",
      "[Iter 176] Train loss: 0.103443\n",
      "[Iter 177] Train loss: 0.103411\n",
      "[Iter 178] Train loss: 0.103380\n",
      "[Iter 179] Train loss: 0.103349\n",
      "[Iter 180] Train loss: 0.103319\n",
      "[Iter 181] Train loss: 0.103291\n",
      "[Iter 182] Train loss: 0.103264\n",
      "[Iter 183] Train loss: 0.103239\n",
      "[Iter 184] Train loss: 0.103215\n",
      "[Iter 185] Train loss: 0.103191\n",
      "[Iter 186] Train loss: 0.103167\n",
      "[Iter 187] Train loss: 0.103143\n",
      "[Iter 188] Train loss: 0.103117\n",
      "[Iter 189] Train loss: 0.103092\n",
      "[Iter 190] Train loss: 0.103067\n",
      "[Iter 191] Train loss: 0.103044\n",
      "[Iter 192] Train loss: 0.103022\n",
      "[Iter 193] Train loss: 0.103000\n",
      "[Iter 194] Train loss: 0.102978\n",
      "[Iter 195] Train loss: 0.102956\n",
      "[Iter 196] Train loss: 0.102934\n",
      "[Iter 197] Train loss: 0.102912\n",
      "[Iter 198] Train loss: 0.102892\n",
      "[Iter 199] Train loss: 0.102871\n",
      "[Iter 200] Train loss: 0.102850\n",
      "[Iter 201] Train loss: 0.102828\n",
      "[Iter 202] Train loss: 0.102805\n",
      "[Iter 203] Train loss: 0.102783\n",
      "[Iter 204] Train loss: 0.102761\n",
      "[Iter 205] Train loss: 0.102741\n",
      "[Iter 206] Train loss: 0.102721\n",
      "[Iter 207] Train loss: 0.102701\n",
      "[Iter 208] Train loss: 0.102683\n",
      "[Iter 209] Train loss: 0.102665\n",
      "[Iter 210] Train loss: 0.102649\n",
      "[Iter 211] Train loss: 0.102633\n",
      "[Iter 212] Train loss: 0.102616\n",
      "[Iter 213] Train loss: 0.102597\n",
      "[Iter 214] Train loss: 0.102580\n",
      "[Iter 215] Train loss: 0.102561\n",
      "[Iter 216] Train loss: 0.102540\n",
      "[Iter 217] Train loss: 0.102521\n",
      "[Iter 218] Train loss: 0.102501\n",
      "[Iter 219] Train loss: 0.102481\n",
      "[Iter 220] Train loss: 0.102462\n",
      "[Iter 221] Train loss: 0.102443\n",
      "[Iter 222] Train loss: 0.102426\n",
      "[Iter 223] Train loss: 0.102408\n",
      "[Iter 224] Train loss: 0.102390\n",
      "[Iter 225] Train loss: 0.102373\n",
      "[Iter 226] Train loss: 0.102357\n",
      "[Iter 227] Train loss: 0.102339\n",
      "[Iter 228] Train loss: 0.102322\n",
      "[Iter 229] Train loss: 0.102305\n",
      "[Iter 230] Train loss: 0.102288\n",
      "[Iter 231] Train loss: 0.102272\n",
      "[Iter 232] Train loss: 0.102257\n",
      "[Iter 233] Train loss: 0.102241\n",
      "[Iter 234] Train loss: 0.102226\n",
      "[Iter 235] Train loss: 0.102212\n",
      "[Iter 236] Train loss: 0.102197\n",
      "[Iter 237] Train loss: 0.102183\n",
      "[Iter 238] Train loss: 0.102169\n",
      "[Iter 239] Train loss: 0.102156\n",
      "[Iter 240] Train loss: 0.102140\n",
      "[Iter 241] Train loss: 0.102123\n",
      "[Iter 242] Train loss: 0.102104\n",
      "[Iter 243] Train loss: 0.102083\n",
      "[Iter 244] Train loss: 0.102062\n",
      "[Iter 245] Train loss: 0.102041\n",
      "[Iter 246] Train loss: 0.102021\n",
      "[Iter 247] Train loss: 0.102002\n",
      "[Iter 248] Train loss: 0.101983\n",
      "[Iter 249] Train loss: 0.101965\n",
      "[Iter 250] Train loss: 0.101946\n",
      "[Iter 251] Train loss: 0.101926\n",
      "[Iter 252] Train loss: 0.101906\n",
      "[Iter 253] Train loss: 0.101887\n",
      "[Iter 254] Train loss: 0.101868\n",
      "[Iter 255] Train loss: 0.101849\n",
      "[Iter 256] Train loss: 0.101832\n",
      "[Iter 257] Train loss: 0.101814\n",
      "[Iter 258] Train loss: 0.101797\n",
      "[Iter 259] Train loss: 0.101779\n",
      "[Iter 260] Train loss: 0.101763\n",
      "[Iter 261] Train loss: 0.101746\n",
      "[Iter 262] Train loss: 0.101730\n",
      "[Iter 263] Train loss: 0.101714\n",
      "[Iter 264] Train loss: 0.101698\n",
      "[Iter 265] Train loss: 0.101683\n",
      "[Iter 266] Train loss: 0.101668\n",
      "[Iter 267] Train loss: 0.101653\n",
      "[Iter 268] Train loss: 0.101639\n",
      "[Iter 269] Train loss: 0.101623\n",
      "[Iter 270] Train loss: 0.101608\n",
      "[Iter 271] Train loss: 0.101594\n",
      "[Iter 272] Train loss: 0.101579\n",
      "[Iter 273] Train loss: 0.101565\n",
      "[Iter 274] Train loss: 0.101551\n",
      "[Iter 275] Train loss: 0.101537\n",
      "[Iter 276] Train loss: 0.101524\n",
      "[Iter 277] Train loss: 0.101511\n",
      "[Iter 278] Train loss: 0.101498\n",
      "[Iter 279] Train loss: 0.101486\n",
      "[Iter 280] Train loss: 0.101475\n",
      "[Iter 281] Train loss: 0.101464\n",
      "[Iter 282] Train loss: 0.101453\n",
      "[Iter 283] Train loss: 0.101443\n",
      "[Iter 284] Train loss: 0.101433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 285] Train loss: 0.101423\n",
      "[Iter 286] Train loss: 0.101414\n",
      "[Iter 287] Train loss: 0.101405\n",
      "[Iter 288] Train loss: 0.101396\n",
      "[Iter 289] Train loss: 0.101387\n",
      "[Iter 290] Train loss: 0.101378\n",
      "[Iter 291] Train loss: 0.101370\n",
      "[Iter 292] Train loss: 0.101361\n",
      "[Iter 293] Train loss: 0.101353\n",
      "[Iter 294] Train loss: 0.101344\n",
      "[Iter 295] Train loss: 0.101336\n",
      "[Iter 296] Train loss: 0.101328\n",
      "[Iter 297] Train loss: 0.101320\n",
      "[Iter 298] Train loss: 0.101311\n",
      "[Iter 299] Train loss: 0.101303\n",
      "[Iter 300] Train loss: 0.101294\n",
      "[Iter 301] Train loss: 0.101286\n",
      "[Iter 302] Train loss: 0.101277\n",
      "[Iter 303] Train loss: 0.101269\n",
      "[Iter 304] Train loss: 0.101260\n",
      "[Iter 305] Train loss: 0.101251\n",
      "[Iter 306] Train loss: 0.101243\n",
      "[Iter 307] Train loss: 0.101234\n",
      "[Iter 308] Train loss: 0.101226\n",
      "[Iter 309] Train loss: 0.101219\n",
      "[Iter 310] Train loss: 0.101211\n",
      "[Iter 311] Train loss: 0.101204\n",
      "[Iter 312] Train loss: 0.101196\n",
      "[Iter 313] Train loss: 0.101189\n",
      "[Iter 314] Train loss: 0.101182\n",
      "[Iter 315] Train loss: 0.101175\n",
      "[Iter 316] Train loss: 0.101168\n",
      "[Iter 317] Train loss: 0.101162\n",
      "[Iter 318] Train loss: 0.101155\n",
      "[Iter 319] Train loss: 0.101149\n",
      "[Iter 320] Train loss: 0.101142\n",
      "[Iter 321] Train loss: 0.101136\n",
      "[Iter 322] Train loss: 0.101129\n",
      "[Iter 323] Train loss: 0.101122\n",
      "[Iter 324] Train loss: 0.101115\n",
      "[Iter 325] Train loss: 0.101108\n",
      "[Iter 326] Train loss: 0.101102\n",
      "[Iter 327] Train loss: 0.101095\n",
      "[Iter 328] Train loss: 0.101089\n",
      "[Iter 329] Train loss: 0.101083\n",
      "[Iter 330] Train loss: 0.101077\n",
      "[Iter 331] Train loss: 0.101071\n",
      "[Iter 332] Train loss: 0.101064\n",
      "[Iter 333] Train loss: 0.101058\n",
      "[Iter 334] Train loss: 0.101052\n",
      "[Iter 335] Train loss: 0.101046\n",
      "[Iter 336] Train loss: 0.101041\n",
      "[Iter 337] Train loss: 0.101035\n",
      "[Iter 338] Train loss: 0.101030\n",
      "[Iter 339] Train loss: 0.101025\n",
      "[Iter 340] Train loss: 0.101020\n",
      "[Iter 341] Train loss: 0.101015\n",
      "[Iter 342] Train loss: 0.101007\n",
      "[Iter 343] Train loss: 0.100999\n",
      "[Iter 344] Train loss: 0.100990\n",
      "[Iter 345] Train loss: 0.100981\n",
      "[Iter 346] Train loss: 0.100974\n",
      "[Iter 347] Train loss: 0.100967\n",
      "[Iter 348] Train loss: 0.100961\n",
      "[Iter 349] Train loss: 0.100956\n",
      "[Iter 350] Train loss: 0.100951\n",
      "[Iter 351] Train loss: 0.100946\n",
      "[Iter 352] Train loss: 0.100940\n",
      "[Iter 353] Train loss: 0.100935\n",
      "[Iter 354] Train loss: 0.100929\n",
      "[Iter 355] Train loss: 0.100924\n",
      "[Iter 356] Train loss: 0.100920\n",
      "[Iter 357] Train loss: 0.100916\n",
      "[Iter 358] Train loss: 0.100913\n",
      "[Iter 359] Train loss: 0.100910\n",
      "[Iter 360] Train loss: 0.100907\n",
      "[Iter 361] Train loss: 0.100904\n",
      "[Iter 362] Train loss: 0.100901\n",
      "[Iter 363] Train loss: 0.100898\n",
      "[Iter 364] Train loss: 0.100895\n",
      "[Iter 365] Train loss: 0.100892\n",
      "[Iter 366] Train loss: 0.100890\n",
      "[Iter 367] Train loss: 0.100887\n",
      "[Iter 368] Train loss: 0.100884\n",
      "[Iter 369] Train loss: 0.100882\n",
      "[Iter 370] Train loss: 0.100879\n",
      "[Iter 371] Train loss: 0.100876\n",
      "[Iter 372] Train loss: 0.100873\n",
      "[Iter 373] Train loss: 0.100871\n",
      "[Iter 374] Train loss: 0.100868\n",
      "[Iter 375] Train loss: 0.100865\n",
      "[Iter 376] Train loss: 0.100861\n",
      "[Iter 377] Train loss: 0.100858\n",
      "[Iter 378] Train loss: 0.100855\n",
      "[Iter 379] Train loss: 0.100852\n",
      "[Iter 380] Train loss: 0.100849\n",
      "[Iter 381] Train loss: 0.100846\n",
      "[Iter 382] Train loss: 0.100843\n",
      "[Iter 383] Train loss: 0.100841\n",
      "[Iter 384] Train loss: 0.100838\n",
      "[Iter 385] Train loss: 0.100835\n",
      "[Iter 386] Train loss: 0.100833\n",
      "[Iter 387] Train loss: 0.100830\n",
      "[Iter 388] Train loss: 0.100828\n",
      "[Iter 389] Train loss: 0.100825\n",
      "[Iter 390] Train loss: 0.100822\n",
      "[Iter 391] Train loss: 0.100820\n",
      "[Iter 392] Train loss: 0.100817\n",
      "[Iter 393] Train loss: 0.100814\n",
      "[Iter 394] Train loss: 0.100812\n",
      "[Iter 395] Train loss: 0.100810\n",
      "[Iter 396] Train loss: 0.100807\n",
      "[Iter 397] Train loss: 0.100805\n",
      "[Iter 398] Train loss: 0.100802\n",
      "[Iter 399] Train loss: 0.100799\n",
      "[Iter 400] Train loss: 0.100797\n",
      "[Iter 401] Train loss: 0.100794\n",
      "[Iter 402] Train loss: 0.100791\n",
      "[Iter 403] Train loss: 0.100788\n",
      "[Iter 404] Train loss: 0.100786\n",
      "[Iter 405] Train loss: 0.100783\n",
      "[Iter 406] Train loss: 0.100780\n",
      "[Iter 407] Train loss: 0.100777\n",
      "[Iter 408] Train loss: 0.100775\n",
      "[Iter 409] Train loss: 0.100772\n",
      "[Iter 410] Train loss: 0.100770\n",
      "[Iter 411] Train loss: 0.100767\n",
      "[Iter 412] Train loss: 0.100765\n",
      "[Iter 413] Train loss: 0.100762\n",
      "[Iter 414] Train loss: 0.100759\n",
      "[Iter 415] Train loss: 0.100756\n",
      "[Iter 416] Train loss: 0.100754\n",
      "[Iter 417] Train loss: 0.100751\n",
      "[Iter 418] Train loss: 0.100749\n",
      "[Iter 419] Train loss: 0.100746\n",
      "[Iter 420] Train loss: 0.100744\n",
      "[Iter 421] Train loss: 0.100742\n",
      "[Iter 422] Train loss: 0.100739\n",
      "[Iter 423] Train loss: 0.100737\n",
      "[Iter 424] Train loss: 0.100734\n",
      "[Iter 425] Train loss: 0.100731\n",
      "[Iter 426] Train loss: 0.100729\n",
      "[Iter 427] Train loss: 0.100726\n",
      "[Iter 428] Train loss: 0.100723\n",
      "[Iter 429] Train loss: 0.100720\n",
      "[Iter 430] Train loss: 0.100718\n",
      "[Iter 431] Train loss: 0.100715\n",
      "[Iter 432] Train loss: 0.100712\n",
      "[Iter 433] Train loss: 0.100710\n",
      "[Iter 434] Train loss: 0.100707\n",
      "[Iter 435] Train loss: 0.100705\n",
      "[Iter 436] Train loss: 0.100702\n",
      "[Iter 437] Train loss: 0.100700\n",
      "[Iter 438] Train loss: 0.100697\n",
      "[Iter 439] Train loss: 0.100695\n",
      "[Iter 440] Train loss: 0.100693\n",
      "[Iter 441] Train loss: 0.100690\n",
      "[Iter 442] Train loss: 0.100688\n",
      "[Iter 443] Train loss: 0.100685\n",
      "[Iter 444] Train loss: 0.100683\n",
      "[Iter 445] Train loss: 0.100680\n",
      "[Iter 446] Train loss: 0.100678\n",
      "[Iter 447] Train loss: 0.100676\n",
      "[Iter 448] Train loss: 0.100673\n",
      "[Iter 449] Train loss: 0.100671\n",
      "[Iter 450] Train loss: 0.100669\n",
      "[Iter 451] Train loss: 0.100667\n",
      "[Iter 452] Train loss: 0.100665\n",
      "[Iter 453] Train loss: 0.100663\n",
      "[Iter 454] Train loss: 0.100662\n",
      "[Iter 455] Train loss: 0.100660\n",
      "[Iter 456] Train loss: 0.100658\n",
      "[Iter 457] Train loss: 0.100657\n",
      "[Iter 458] Train loss: 0.100655\n",
      "[Iter 459] Train loss: 0.100654\n",
      "[Iter 460] Train loss: 0.100653\n",
      "[Iter 461] Train loss: 0.100651\n",
      "[Iter 462] Train loss: 0.100650\n",
      "[Iter 463] Train loss: 0.100649\n",
      "[Iter 464] Train loss: 0.100647\n",
      "[Iter 465] Train loss: 0.100646\n",
      "[Iter 466] Train loss: 0.100645\n",
      "[Iter 467] Train loss: 0.100644\n",
      "[Iter 468] Train loss: 0.100643\n",
      "[Iter 469] Train loss: 0.100641\n",
      "[Iter 470] Train loss: 0.100640\n",
      "[Iter 471] Train loss: 0.100639\n",
      "[Iter 472] Train loss: 0.100638\n",
      "[Iter 473] Train loss: 0.100637\n",
      "[Iter 474] Train loss: 0.100636\n",
      "[Iter 475] Train loss: 0.100635\n",
      "[Iter 476] Train loss: 0.100633\n",
      "[Iter 477] Train loss: 0.100632\n",
      "[Iter 478] Train loss: 0.100631\n",
      "[Iter 479] Train loss: 0.100630\n",
      "[Iter 480] Train loss: 0.100628\n",
      "[Iter 481] Train loss: 0.100627\n",
      "[Iter 482] Train loss: 0.100626\n",
      "[Iter 483] Train loss: 0.100625\n",
      "[Iter 484] Train loss: 0.100623\n",
      "[Iter 485] Train loss: 0.100622\n",
      "[Iter 486] Train loss: 0.100621\n",
      "[Iter 487] Train loss: 0.100619\n",
      "[Iter 488] Train loss: 0.100618\n",
      "[Iter 489] Train loss: 0.100617\n",
      "[Iter 490] Train loss: 0.100616\n",
      "[Iter 491] Train loss: 0.100614\n",
      "[Iter 492] Train loss: 0.100613\n",
      "[Iter 493] Train loss: 0.100612\n",
      "[Iter 494] Train loss: 0.100611\n",
      "[Iter 495] Train loss: 0.100610\n",
      "[Iter 496] Train loss: 0.100609\n",
      "[Iter 497] Train loss: 0.100607\n",
      "[Iter 498] Train loss: 0.100606\n",
      "[Iter 499] Train loss: 0.100605\n",
      "[Iter 500] Train loss: 0.100604\n",
      "[Iter 501] Train loss: 0.100603\n",
      "[Iter 502] Train loss: 0.100602\n",
      "[Iter 503] Train loss: 0.100601\n",
      "[Iter 504] Train loss: 0.100600\n",
      "[Iter 505] Train loss: 0.100599\n",
      "[Iter 506] Train loss: 0.100598\n",
      "[Iter 507] Train loss: 0.100597\n",
      "[Iter 508] Train loss: 0.100596\n",
      "[Iter 509] Train loss: 0.100595\n",
      "[Iter 510] Train loss: 0.100594\n",
      "[Iter 511] Train loss: 0.100593\n",
      "[Iter 512] Train loss: 0.100592\n",
      "[Iter 513] Train loss: 0.100591\n",
      "[Iter 514] Train loss: 0.100591\n",
      "[Iter 515] Train loss: 0.100590\n",
      "[Iter 516] Train loss: 0.100589\n",
      "[Iter 517] Train loss: 0.100588\n",
      "[Iter 518] Train loss: 0.100587\n",
      "[Iter 519] Train loss: 0.100587\n",
      "[Iter 520] Train loss: 0.100586\n",
      "[Iter 521] Train loss: 0.100585\n",
      "[Iter 522] Train loss: 0.100584\n",
      "[Iter 523] Train loss: 0.100584\n",
      "[Iter 524] Train loss: 0.100583\n",
      "[Iter 525] Train loss: 0.100583\n",
      "[Iter 526] Train loss: 0.100582\n",
      "[Iter 527] Train loss: 0.100581\n",
      "[Iter 528] Train loss: 0.100581\n",
      "[Iter 529] Train loss: 0.100580\n",
      "[Iter 530] Train loss: 0.100580\n",
      "[Iter 531] Train loss: 0.100579\n",
      "[Iter 532] Train loss: 0.100579\n",
      "[Iter 533] Train loss: 0.100578\n",
      "[Iter 534] Train loss: 0.100578\n",
      "[Iter 535] Train loss: 0.100578\n",
      "[Iter 536] Train loss: 0.100577\n",
      "[Iter 537] Train loss: 0.100577\n",
      "[Iter 538] Train loss: 0.100576\n",
      "[Iter 539] Train loss: 0.100576\n",
      "[Iter 540] Train loss: 0.100576\n",
      "[Iter 541] Train loss: 0.100575\n",
      "[Iter 542] Train loss: 0.100575\n",
      "[Iter 543] Train loss: 0.100574\n",
      "[Iter 544] Train loss: 0.100574\n",
      "[Iter 545] Train loss: 0.100574\n",
      "[Iter 546] Train loss: 0.100573\n",
      "[Iter 547] Train loss: 0.100573\n",
      "[Iter 548] Train loss: 0.100573\n",
      "[Iter 549] Train loss: 0.100572\n",
      "[Iter 550] Train loss: 0.100572\n",
      "[Iter 551] Train loss: 0.100572\n",
      "[Iter 552] Train loss: 0.100571\n",
      "[Iter 553] Train loss: 0.100571\n",
      "[Iter 554] Train loss: 0.100571\n",
      "[Iter 555] Train loss: 0.100570\n",
      "[Iter 556] Train loss: 0.100570\n",
      "[Iter 557] Train loss: 0.100570\n",
      "[Iter 558] Train loss: 0.100569\n",
      "[Iter 559] Train loss: 0.100569\n",
      "[Iter 560] Train loss: 0.100569\n",
      "[Iter 561] Train loss: 0.100569\n",
      "[Iter 562] Train loss: 0.100568\n",
      "[Iter 563] Train loss: 0.100568\n",
      "[Iter 564] Train loss: 0.100568\n",
      "[Iter 565] Train loss: 0.100568\n",
      "[Iter 566] Train loss: 0.100567\n",
      "[Iter 567] Train loss: 0.100567\n",
      "[Iter 568] Train loss: 0.100567\n",
      "[Iter 569] Train loss: 0.100566\n",
      "[Iter 570] Train loss: 0.100566\n",
      "[Iter 571] Train loss: 0.100566\n",
      "[Iter 572] Train loss: 0.100566\n",
      "[Iter 573] Train loss: 0.100565\n",
      "[Iter 574] Train loss: 0.100565\n",
      "[Iter 575] Train loss: 0.100565\n",
      "[Iter 576] Train loss: 0.100565\n",
      "[Iter 577] Train loss: 0.100564\n",
      "[Iter 578] Train loss: 0.100564\n",
      "[Iter 579] Train loss: 0.100564\n",
      "[Iter 580] Train loss: 0.100563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 581] Train loss: 0.100563\n",
      "[Iter 582] Train loss: 0.100563\n",
      "[Iter 583] Train loss: 0.100563\n",
      "[Iter 584] Train loss: 0.100562\n",
      "[Iter 585] Train loss: 0.100562\n",
      "[Iter 586] Train loss: 0.100562\n",
      "[Iter 587] Train loss: 0.100560\n",
      "[Iter 588] Train loss: 0.100558\n",
      "[Iter 589] Train loss: 0.100555\n",
      "[Iter 590] Train loss: 0.100552\n",
      "[Iter 591] Train loss: 0.100549\n",
      "[Iter 592] Train loss: 0.100547\n",
      "[Iter 593] Train loss: 0.100544\n",
      "[Iter 594] Train loss: 0.100538\n",
      "[Iter 595] Train loss: 0.100532\n",
      "[Iter 596] Train loss: 0.100527\n",
      "[Iter 597] Train loss: 0.100522\n",
      "[Iter 598] Train loss: 0.100518\n",
      "[Iter 599] Train loss: 0.100515\n",
      "[Iter 600] Train loss: 0.100512\n",
      "[Iter 601] Train loss: 0.100510\n",
      "[Iter 602] Train loss: 0.100507\n",
      "[Iter 603] Train loss: 0.100505\n",
      "[Iter 604] Train loss: 0.100503\n",
      "[Iter 605] Train loss: 0.100500\n",
      "[Iter 606] Train loss: 0.100498\n",
      "[Iter 607] Train loss: 0.100497\n",
      "[Iter 608] Train loss: 0.100495\n",
      "[Iter 609] Train loss: 0.100494\n",
      "[Iter 610] Train loss: 0.100493\n",
      "[Iter 611] Train loss: 0.100492\n",
      "[Iter 612] Train loss: 0.100491\n",
      "[Iter 613] Train loss: 0.100490\n",
      "[Iter 614] Train loss: 0.100489\n",
      "[Iter 615] Train loss: 0.100487\n",
      "[Iter 616] Train loss: 0.100486\n",
      "[Iter 617] Train loss: 0.100485\n",
      "[Iter 618] Train loss: 0.100484\n",
      "[Iter 619] Train loss: 0.100483\n",
      "[Iter 620] Train loss: 0.100482\n",
      "[Iter 621] Train loss: 0.100481\n",
      "[Iter 622] Train loss: 0.100480\n",
      "[Iter 623] Train loss: 0.100480\n",
      "[Iter 624] Train loss: 0.100479\n",
      "[Iter 625] Train loss: 0.100478\n",
      "[Iter 626] Train loss: 0.100477\n",
      "[Iter 627] Train loss: 0.100477\n",
      "[Iter 628] Train loss: 0.100476\n",
      "[Iter 629] Train loss: 0.100475\n",
      "[Iter 630] Train loss: 0.100474\n",
      "[Iter 631] Train loss: 0.100473\n",
      "[Iter 632] Train loss: 0.100473\n",
      "[Iter 633] Train loss: 0.100472\n",
      "[Iter 634] Train loss: 0.100471\n",
      "[Iter 635] Train loss: 0.100471\n",
      "[Iter 636] Train loss: 0.100470\n",
      "[Iter 637] Train loss: 0.100469\n",
      "[Iter 638] Train loss: 0.100469\n",
      "[Iter 639] Train loss: 0.100468\n",
      "[Iter 640] Train loss: 0.100467\n",
      "[Iter 641] Train loss: 0.100467\n",
      "[Iter 642] Train loss: 0.100466\n",
      "[Iter 643] Train loss: 0.100465\n",
      "[Iter 644] Train loss: 0.100465\n",
      "[Iter 645] Train loss: 0.100464\n",
      "[Iter 646] Train loss: 0.100463\n",
      "[Iter 647] Train loss: 0.100463\n",
      "[Iter 648] Train loss: 0.100462\n",
      "[Iter 649] Train loss: 0.100461\n",
      "[Iter 650] Train loss: 0.100461\n",
      "[Iter 651] Train loss: 0.100460\n",
      "[Iter 652] Train loss: 0.100460\n",
      "[Iter 653] Train loss: 0.100459\n",
      "[Iter 654] Train loss: 0.100458\n",
      "[Iter 655] Train loss: 0.100458\n",
      "[Iter 656] Train loss: 0.100457\n",
      "[Iter 657] Train loss: 0.100457\n",
      "[Iter 658] Train loss: 0.100456\n",
      "[Iter 659] Train loss: 0.100456\n",
      "[Iter 660] Train loss: 0.100455\n",
      "[Iter 661] Train loss: 0.100455\n",
      "[Iter 662] Train loss: 0.100454\n",
      "[Iter 663] Train loss: 0.100454\n",
      "[Iter 664] Train loss: 0.100453\n",
      "[Iter 665] Train loss: 0.100453\n",
      "[Iter 666] Train loss: 0.100452\n",
      "[Iter 667] Train loss: 0.100452\n",
      "[Iter 668] Train loss: 0.100451\n",
      "[Iter 669] Train loss: 0.100450\n",
      "[Iter 670] Train loss: 0.100450\n",
      "[Iter 671] Train loss: 0.100449\n",
      "[Iter 672] Train loss: 0.100449\n",
      "[Iter 673] Train loss: 0.100448\n",
      "[Iter 674] Train loss: 0.100448\n",
      "[Iter 675] Train loss: 0.100447\n",
      "[Iter 676] Train loss: 0.100447\n",
      "[Iter 677] Train loss: 0.100445\n",
      "[Iter 678] Train loss: 0.100442\n",
      "[Iter 679] Train loss: 0.100439\n",
      "[Iter 680] Train loss: 0.100436\n",
      "[Iter 681] Train loss: 0.100433\n",
      "[Iter 682] Train loss: 0.100429\n",
      "[Iter 683] Train loss: 0.100422\n",
      "[Iter 684] Train loss: 0.100414\n",
      "[Iter 685] Train loss: 0.100408\n",
      "[Iter 686] Train loss: 0.100402\n",
      "[Iter 687] Train loss: 0.100398\n",
      "[Iter 688] Train loss: 0.100394\n",
      "[Iter 689] Train loss: 0.100391\n",
      "[Iter 690] Train loss: 0.100388\n",
      "[Iter 691] Train loss: 0.100385\n",
      "[Iter 692] Train loss: 0.100382\n",
      "[Iter 693] Train loss: 0.100379\n",
      "[Iter 694] Train loss: 0.100376\n",
      "[Iter 695] Train loss: 0.100373\n",
      "[Iter 696] Train loss: 0.100371\n",
      "[Iter 697] Train loss: 0.100368\n",
      "[Iter 698] Train loss: 0.100367\n",
      "[Iter 699] Train loss: 0.100365\n",
      "[Iter 700] Train loss: 0.100364\n",
      "[Iter 701] Train loss: 0.100362\n",
      "[Iter 702] Train loss: 0.100361\n",
      "[Iter 703] Train loss: 0.100360\n",
      "[Iter 704] Train loss: 0.100358\n",
      "[Iter 705] Train loss: 0.100357\n",
      "[Iter 706] Train loss: 0.100355\n",
      "[Iter 707] Train loss: 0.100354\n",
      "[Iter 708] Train loss: 0.100353\n",
      "[Iter 709] Train loss: 0.100352\n",
      "[Iter 710] Train loss: 0.100350\n",
      "[Iter 711] Train loss: 0.100349\n",
      "[Iter 712] Train loss: 0.100348\n",
      "[Iter 713] Train loss: 0.100348\n",
      "[Iter 714] Train loss: 0.100347\n",
      "[Iter 715] Train loss: 0.100346\n",
      "[Iter 716] Train loss: 0.100346\n",
      "[Iter 717] Train loss: 0.100345\n",
      "[Iter 718] Train loss: 0.100344\n",
      "[Iter 719] Train loss: 0.100344\n",
      "[Iter 720] Train loss: 0.100343\n",
      "[Iter 721] Train loss: 0.100343\n",
      "[Iter 722] Train loss: 0.100342\n",
      "[Iter 723] Train loss: 0.100341\n",
      "[Iter 724] Train loss: 0.100341\n",
      "[Iter 725] Train loss: 0.100341\n",
      "[Iter 726] Train loss: 0.100340\n",
      "[Iter 727] Train loss: 0.100340\n",
      "[Iter 728] Train loss: 0.100339\n",
      "[Iter 729] Train loss: 0.100339\n",
      "[Iter 730] Train loss: 0.100338\n",
      "[Iter 731] Train loss: 0.100338\n",
      "[Iter 732] Train loss: 0.100337\n",
      "[Iter 733] Train loss: 0.100337\n",
      "[Iter 734] Train loss: 0.100336\n",
      "[Iter 735] Train loss: 0.100336\n",
      "[Iter 736] Train loss: 0.100335\n",
      "[Iter 737] Train loss: 0.100335\n",
      "[Iter 738] Train loss: 0.100334\n",
      "[Iter 739] Train loss: 0.100334\n",
      "[Iter 740] Train loss: 0.100333\n",
      "[Iter 741] Train loss: 0.100333\n",
      "[Iter 742] Train loss: 0.100333\n",
      "[Iter 743] Train loss: 0.100332\n",
      "[Iter 744] Train loss: 0.100332\n",
      "[Iter 745] Train loss: 0.100332\n",
      "[Iter 746] Train loss: 0.100331\n",
      "[Iter 747] Train loss: 0.100331\n",
      "[Iter 748] Train loss: 0.100330\n",
      "[Iter 749] Train loss: 0.100330\n",
      "[Iter 750] Train loss: 0.100330\n",
      "[Iter 751] Train loss: 0.100329\n",
      "[Iter 752] Train loss: 0.100329\n",
      "[Iter 753] Train loss: 0.100329\n",
      "[Iter 754] Train loss: 0.100328\n",
      "[Iter 755] Train loss: 0.100328\n",
      "[Iter 756] Train loss: 0.100328\n",
      "[Iter 757] Train loss: 0.100328\n",
      "[Iter 758] Train loss: 0.100327\n",
      "[Iter 759] Train loss: 0.100327\n",
      "[Iter 760] Train loss: 0.100327\n",
      "[Iter 761] Train loss: 0.100326\n",
      "[Iter 762] Train loss: 0.100326\n",
      "[Iter 763] Train loss: 0.100326\n",
      "[Iter 764] Train loss: 0.100325\n",
      "[Iter 765] Train loss: 0.100325\n",
      "[Iter 766] Train loss: 0.100325\n",
      "[Iter 767] Train loss: 0.100323\n",
      "[Iter 768] Train loss: 0.100321\n",
      "[Iter 769] Train loss: 0.100318\n",
      "[Iter 770] Train loss: 0.100316\n",
      "[Iter 771] Train loss: 0.100313\n",
      "[Iter 772] Train loss: 0.100311\n",
      "[Iter 773] Train loss: 0.100309\n",
      "[Iter 774] Train loss: 0.100308\n",
      "[Iter 775] Train loss: 0.100307\n",
      "[Iter 776] Train loss: 0.100306\n",
      "[Iter 777] Train loss: 0.100305\n",
      "[Iter 778] Train loss: 0.100304\n",
      "[Iter 779] Train loss: 0.100303\n",
      "[Iter 780] Train loss: 0.100301\n",
      "[Iter 781] Train loss: 0.100300\n",
      "[Iter 782] Train loss: 0.100299\n",
      "[Iter 783] Train loss: 0.100298\n",
      "[Iter 784] Train loss: 0.100297\n",
      "[Iter 785] Train loss: 0.100296\n",
      "[Iter 786] Train loss: 0.100295\n",
      "[Iter 787] Train loss: 0.100295\n",
      "[Iter 788] Train loss: 0.100294\n",
      "[Iter 789] Train loss: 0.100293\n",
      "[Iter 790] Train loss: 0.100293\n",
      "[Iter 791] Train loss: 0.100292\n",
      "[Iter 792] Train loss: 0.100291\n",
      "[Iter 793] Train loss: 0.100290\n",
      "[Iter 794] Train loss: 0.100289\n",
      "[Iter 795] Train loss: 0.100288\n",
      "[Iter 796] Train loss: 0.100287\n",
      "[Iter 797] Train loss: 0.100286\n",
      "[Iter 798] Train loss: 0.100286\n",
      "[Iter 799] Train loss: 0.100285\n",
      "[Iter 800] Train loss: 0.100285\n",
      "[Iter 801] Train loss: 0.100284\n",
      "[Iter 802] Train loss: 0.100284\n",
      "[Iter 803] Train loss: 0.100283\n",
      "[Iter 804] Train loss: 0.100283\n",
      "[Iter 805] Train loss: 0.100282\n",
      "[Iter 806] Train loss: 0.100282\n",
      "[Iter 807] Train loss: 0.100281\n",
      "[Iter 808] Train loss: 0.100281\n",
      "[Iter 809] Train loss: 0.100280\n",
      "[Iter 810] Train loss: 0.100280\n",
      "[Iter 811] Train loss: 0.100279\n",
      "[Iter 812] Train loss: 0.100279\n",
      "[Iter 813] Train loss: 0.100278\n",
      "[Iter 814] Train loss: 0.100278\n",
      "[Iter 815] Train loss: 0.100277\n",
      "[Iter 816] Train loss: 0.100277\n",
      "[Iter 817] Train loss: 0.100276\n",
      "[Iter 818] Train loss: 0.100276\n",
      "[Iter 819] Train loss: 0.100276\n",
      "[Iter 820] Train loss: 0.100275\n",
      "[Iter 821] Train loss: 0.100275\n",
      "[Iter 822] Train loss: 0.100274\n",
      "[Iter 823] Train loss: 0.100274\n",
      "[Iter 824] Train loss: 0.100274\n",
      "[Iter 825] Train loss: 0.100273\n",
      "[Iter 826] Train loss: 0.100273\n",
      "[Iter 827] Train loss: 0.100273\n",
      "[Iter 828] Train loss: 0.100273\n",
      "[Iter 829] Train loss: 0.100272\n",
      "[Iter 830] Train loss: 0.100272\n",
      "[Iter 831] Train loss: 0.100272\n",
      "[Iter 832] Train loss: 0.100272\n",
      "[Iter 833] Train loss: 0.100271\n",
      "[Iter 834] Train loss: 0.100271\n",
      "[Iter 835] Train loss: 0.100271\n",
      "[Iter 836] Train loss: 0.100271\n",
      "[Iter 837] Train loss: 0.100270\n",
      "[Iter 838] Train loss: 0.100270\n",
      "[Iter 839] Train loss: 0.100270\n",
      "[Iter 840] Train loss: 0.100270\n",
      "[Iter 841] Train loss: 0.100270\n",
      "[Iter 842] Train loss: 0.100269\n",
      "[Iter 843] Train loss: 0.100269\n",
      "[Iter 844] Train loss: 0.100269\n",
      "[Iter 845] Train loss: 0.100269\n",
      "[Iter 846] Train loss: 0.100269\n",
      "[Iter 847] Train loss: 0.100269\n",
      "[Iter 848] Train loss: 0.100268\n",
      "[Iter 849] Train loss: 0.100268\n",
      "[Iter 850] Train loss: 0.100268\n",
      "[Iter 851] Train loss: 0.100268\n",
      "[Iter 852] Train loss: 0.100268\n",
      "[Iter 853] Train loss: 0.100268\n",
      "[Iter 854] Train loss: 0.100267\n",
      "[Iter 855] Train loss: 0.100267\n",
      "[Iter 856] Train loss: 0.100267\n",
      "[Iter 857] Train loss: 0.100267\n",
      "[Iter 858] Train loss: 0.100267\n",
      "[Iter 859] Train loss: 0.100267\n",
      "[Iter 860] Train loss: 0.100266\n",
      "[Iter 861] Train loss: 0.100266\n",
      "[Iter 862] Train loss: 0.100266\n",
      "[Iter 863] Train loss: 0.100266\n",
      "[Iter 864] Train loss: 0.100266\n",
      "[Iter 865] Train loss: 0.100266\n",
      "[Iter 866] Train loss: 0.100265\n",
      "[Iter 867] Train loss: 0.100265\n",
      "[Iter 868] Train loss: 0.100265\n",
      "[Iter 869] Train loss: 0.100265\n",
      "[Iter 870] Train loss: 0.100265\n",
      "[Iter 871] Train loss: 0.100265\n",
      "[Iter 872] Train loss: 0.100264\n",
      "[Iter 873] Train loss: 0.100264\n",
      "[Iter 874] Train loss: 0.100264\n",
      "[Iter 875] Train loss: 0.100264\n",
      "[Iter 876] Train loss: 0.100264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 877] Train loss: 0.100264\n",
      "[Iter 878] Train loss: 0.100264\n",
      "[Iter 879] Train loss: 0.100263\n",
      "[Iter 880] Train loss: 0.100263\n",
      "[Iter 881] Train loss: 0.100263\n",
      "[Iter 882] Train loss: 0.100263\n",
      "[Iter 883] Train loss: 0.100263\n",
      "[Iter 884] Train loss: 0.100263\n",
      "[Iter 885] Train loss: 0.100263\n",
      "[Iter 886] Train loss: 0.100263\n",
      "[Iter 887] Train loss: 0.100262\n",
      "[Iter 888] Train loss: 0.100262\n",
      "[Iter 889] Train loss: 0.100262\n",
      "[Iter 890] Train loss: 0.100262\n",
      "[Iter 891] Train loss: 0.100262\n",
      "[Iter 892] Train loss: 0.100262\n",
      "[Iter 893] Train loss: 0.100262\n",
      "[Iter 894] Train loss: 0.100262\n",
      "[Iter 895] Train loss: 0.100262\n",
      "[Iter 896] Train loss: 0.100262\n",
      "[Iter 897] Train loss: 0.100261\n",
      "[Iter 898] Train loss: 0.100261\n",
      "[Iter 899] Train loss: 0.100261\n",
      "[Iter 900] Train loss: 0.100261\n",
      "[Iter 901] Train loss: 0.100261\n",
      "[Iter 902] Train loss: 0.100261\n",
      "[Iter 903] Train loss: 0.100261\n",
      "[Iter 904] Train loss: 0.100261\n",
      "[Iter 905] Train loss: 0.100261\n",
      "[Iter 906] Train loss: 0.100261\n",
      "[Iter 907] Train loss: 0.100261\n",
      "[Iter 908] Train loss: 0.100261\n",
      "[Iter 909] Train loss: 0.100261\n",
      "[Iter 910] Train loss: 0.100261\n",
      "[Iter 911] Train loss: 0.100260\n",
      "[Iter 912] Train loss: 0.100260\n",
      "[Iter 913] Train loss: 0.100260\n",
      "[Iter 914] Train loss: 0.100260\n",
      "[Iter 915] Train loss: 0.100260\n",
      "[Iter 916] Train loss: 0.100260\n",
      "[Iter 917] Train loss: 0.100260\n",
      "[Iter 918] Train loss: 0.100260\n",
      "[Iter 919] Train loss: 0.100260\n",
      "[Iter 920] Train loss: 0.100260\n",
      "[Iter 921] Train loss: 0.100260\n",
      "[Iter 922] Train loss: 0.100260\n",
      "[Iter 923] Train loss: 0.100260\n",
      "[Iter 924] Train loss: 0.100260\n",
      "[Iter 925] Train loss: 0.100259\n",
      "[Iter 926] Train loss: 0.100259\n",
      "[Iter 927] Train loss: 0.100259\n",
      "[Iter 928] Train loss: 0.100259\n",
      "[Iter 929] Train loss: 0.100259\n",
      "[Iter 930] Train loss: 0.100259\n",
      "[Iter 931] Train loss: 0.100259\n",
      "[Iter 932] Train loss: 0.100259\n",
      "[Iter 933] Train loss: 0.100259\n",
      "[Iter 934] Train loss: 0.100259\n",
      "[Iter 935] Train loss: 0.100259\n",
      "[Iter 936] Train loss: 0.100259\n",
      "[Iter 937] Train loss: 0.100259\n",
      "[Iter 938] Train loss: 0.100259\n",
      "[Iter 939] Train loss: 0.100259\n",
      "[Iter 940] Train loss: 0.100259\n",
      "[Iter 941] Train loss: 0.100259\n",
      "[Iter 942] Train loss: 0.100258\n",
      "[Iter 943] Train loss: 0.100258\n",
      "[Iter 944] Train loss: 0.100258\n",
      "[Iter 945] Train loss: 0.100258\n",
      "[Iter 946] Train loss: 0.100258\n",
      "[Iter 947] Train loss: 0.100258\n",
      "[Iter 948] Train loss: 0.100258\n",
      "[Iter 949] Train loss: 0.100258\n",
      "[Iter 950] Train loss: 0.100258\n",
      "[Iter 951] Train loss: 0.100258\n",
      "[Iter 952] Train loss: 0.100258\n",
      "[Iter 953] Train loss: 0.100258\n",
      "[Iter 954] Train loss: 0.100258\n",
      "[Iter 955] Train loss: 0.100258\n",
      "[Iter 956] Train loss: 0.100258\n",
      "[Iter 957] Train loss: 0.100258\n",
      "[Iter 958] Train loss: 0.100258\n",
      "[Iter 959] Train loss: 0.100258\n",
      "[Iter 960] Train loss: 0.100258\n",
      "[Iter 961] Train loss: 0.100258\n",
      "[Iter 962] Train loss: 0.100258\n",
      "[Iter 963] Train loss: 0.100258\n",
      "[Iter 964] Train loss: 0.100257\n",
      "[Iter 965] Train loss: 0.100257\n",
      "[Iter 966] Train loss: 0.100257\n",
      "[Iter 967] Train loss: 0.100257\n",
      "[Iter 968] Train loss: 0.100257\n",
      "[Iter 969] Train loss: 0.100257\n",
      "[Iter 970] Train loss: 0.100257\n",
      "[Iter 971] Train loss: 0.100257\n",
      "[Iter 972] Train loss: 0.100257\n",
      "[Iter 973] Train loss: 0.100257\n",
      "[Iter 974] Train loss: 0.100257\n",
      "[Iter 975] Train loss: 0.100257\n",
      "[Iter 976] Train loss: 0.100257\n",
      "[Iter 977] Train loss: 0.100257\n",
      "[Iter 978] Train loss: 0.100257\n",
      "[Iter 979] Train loss: 0.100257\n",
      "[Iter 980] Train loss: 0.100257\n",
      "[Iter 981] Train loss: 0.100257\n",
      "[Iter 982] Train loss: 0.100257\n",
      "[Iter 983] Train loss: 0.100257\n",
      "[Iter 984] Train loss: 0.100257\n",
      "[Iter 985] Train loss: 0.100257\n",
      "[Iter 986] Train loss: 0.100257\n",
      "[Iter 987] Train loss: 0.100257\n",
      "[Iter 988] Train loss: 0.100257\n",
      "[Iter 989] Train loss: 0.100256\n",
      "[Iter 990] Train loss: 0.100256\n",
      "[Iter 991] Train loss: 0.100256\n",
      "[Iter 992] Train loss: 0.100256\n",
      "[Iter 993] Train loss: 0.100256\n",
      "[Iter 994] Train loss: 0.100256\n",
      "[Iter 995] Train loss: 0.100256\n",
      "[Iter 996] Train loss: 0.100256\n",
      "[Iter 997] Train loss: 0.100256\n",
      "[Iter 998] Train loss: 0.100256\n",
      "[Iter 999] Train loss: 0.100256\n"
     ]
    }
   ],
   "source": [
    "classification(train_X, train_Y, val_X, val_Y, test_X, test_Y, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Kết quả phân nhóm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
